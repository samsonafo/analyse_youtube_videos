{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samson.afolabi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>category_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>channel_description</th>\n",
       "      <th>published_at</th>\n",
       "      <th>channel_creation_date</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>weighted_views</th>\n",
       "      <th>length_category</th>\n",
       "      <th>upload_day</th>\n",
       "      <th>upload_hour</th>\n",
       "      <th>title_length</th>\n",
       "      <th>description_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2XLnR2HlmBU</td>\n",
       "      <td>Compact Verbot: Faeser massiv unter Druck!</td>\n",
       "      <td>Prof. Vosgerau übt massive Kritik an Faesers C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>27</td>\n",
       "      <td>71231</td>\n",
       "      <td>11255</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>PT10M32S</td>\n",
       "      <td>...</td>\n",
       "      <td>Ich erstelle Videos über Dinge, die mich beweg...</td>\n",
       "      <td>2013-11-28T10:40:22Z</td>\n",
       "      <td>2013-11-28T10:40:22Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SjnWd_j7wZQ</td>\n",
       "      <td>ن سوشل میڈیا کی PTI خاتون MNA کی جعلی گندی وڈی...</td>\n",
       "      <td>Today's Punjabi Vlog: https://www.youtube.com/...</td>\n",
       "      <td>['shahbaz gill', 'shehbaz gill', 'urdu vlog', ...</td>\n",
       "      <td>25</td>\n",
       "      <td>191438</td>\n",
       "      <td>22657</td>\n",
       "      <td>0</td>\n",
       "      <td>2894</td>\n",
       "      <td>PT25M17S</td>\n",
       "      <td>...</td>\n",
       "      <td>This channel covers News &amp; Current Affairs\\n\\n...</td>\n",
       "      <td>2019-06-02T20:41:32Z</td>\n",
       "      <td>2019-06-02T20:41:32Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XFTuRBkb8r8</td>\n",
       "      <td>Thailand Vlog / DAY 7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>30639</td>\n",
       "      <td>7874</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>PT1M1S</td>\n",
       "      <td>...</td>\n",
       "      <td>Hey there!\\nMy name is Nirami :) \\nI´m gonna t...</td>\n",
       "      <td>2012-07-30T09:27:07Z</td>\n",
       "      <td>2012-07-30T09:27:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahIN1hCdjeQ</td>\n",
       "      <td>Buying a Gaming PC from Facebook Marketplace I...</td>\n",
       "      <td>Check out the ZimaBlade below!\\nZimaBlade Offi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>43212</td>\n",
       "      <td>7229</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>PT11M30S</td>\n",
       "      <td>...</td>\n",
       "      <td>Hi, I'm Andy! I own a computer repair shop in ...</td>\n",
       "      <td>2014-10-15T21:30:10Z</td>\n",
       "      <td>2014-10-15T21:30:10Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM7SROtdvlo</td>\n",
       "      <td>Drivers stuck between L.A. and Las Vegas as I-...</td>\n",
       "      <td>An overturned big rig and resulting hazmat sit...</td>\n",
       "      <td>['video', 'news']</td>\n",
       "      <td>25</td>\n",
       "      <td>152033</td>\n",
       "      <td>1427</td>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "      <td>PT5M2S</td>\n",
       "      <td>...</td>\n",
       "      <td>KTLA 5 in Los Angeles covers breaking news, we...</td>\n",
       "      <td>2006-06-13T05:19:22Z</td>\n",
       "      <td>2006-06-13T05:19:22Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  2XLnR2HlmBU         Compact Verbot: Faeser massiv unter Druck!   \n",
       "1  SjnWd_j7wZQ  ن سوشل میڈیا کی PTI خاتون MNA کی جعلی گندی وڈی...   \n",
       "2  XFTuRBkb8r8                              Thailand Vlog / DAY 7   \n",
       "3  ahIN1hCdjeQ  Buying a Gaming PC from Facebook Marketplace I...   \n",
       "4  IM7SROtdvlo  Drivers stuck between L.A. and Las Vegas as I-...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Prof. Vosgerau übt massive Kritik an Faesers C...   \n",
       "1  Today's Punjabi Vlog: https://www.youtube.com/...   \n",
       "2                                                NaN   \n",
       "3  Check out the ZimaBlade below!\\nZimaBlade Offi...   \n",
       "4  An overturned big rig and resulting hazmat sit...   \n",
       "\n",
       "                                                tags  category_id  view_count  \\\n",
       "0                                                 []           27       71231   \n",
       "1  ['shahbaz gill', 'shehbaz gill', 'urdu vlog', ...           25      191438   \n",
       "2                                                 []            1       30639   \n",
       "3                                                 []           28       43212   \n",
       "4                                  ['video', 'news']           25      152033   \n",
       "\n",
       "   like_count  dislike_count  comment_count  duration  ...  \\\n",
       "0       11255              0            953  PT10M32S  ...   \n",
       "1       22657              0           2894  PT25M17S  ...   \n",
       "2        7874              0            147    PT1M1S  ...   \n",
       "3        7229              0            411  PT11M30S  ...   \n",
       "4        1427              0            657    PT5M2S  ...   \n",
       "\n",
       "                                 channel_description          published_at  \\\n",
       "0  Ich erstelle Videos über Dinge, die mich beweg...  2013-11-28T10:40:22Z   \n",
       "1  This channel covers News & Current Affairs\\n\\n...  2019-06-02T20:41:32Z   \n",
       "2  Hey there!\\nMy name is Nirami :) \\nI´m gonna t...  2012-07-30T09:27:07Z   \n",
       "3  Hi, I'm Andy! I own a computer repair shop in ...  2014-10-15T21:30:10Z   \n",
       "4  KTLA 5 in Los Angeles covers breaking news, we...  2006-06-13T05:19:22Z   \n",
       "\n",
       "  channel_creation_date duration_seconds weighted_views  length_category  \\\n",
       "0  2013-11-28T10:40:22Z              NaN            NaN              NaN   \n",
       "1  2019-06-02T20:41:32Z              NaN            NaN              NaN   \n",
       "2  2012-07-30T09:27:07Z              NaN            NaN              NaN   \n",
       "3  2014-10-15T21:30:10Z              NaN            NaN              NaN   \n",
       "4  2006-06-13T05:19:22Z              NaN            NaN              NaN   \n",
       "\n",
       "   upload_day  upload_hour title_length description_length  \n",
       "0         NaN          NaN          NaN                NaN  \n",
       "1         NaN          NaN          NaN                NaN  \n",
       "2         NaN          NaN          NaN                NaN  \n",
       "3         NaN          NaN          NaN                NaN  \n",
       "4         NaN          NaN          NaN                NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import isodate\n",
    "import joblib\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the new dataset\n",
    "file_path = 'new_youtube_video.csv'\n",
    "youtube_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows to understand the structure\n",
    "youtube_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect Arabic script in text\n",
    "def contains_arabic(text):\n",
    "    arabic_characters = re.compile(\"[\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF]\")\n",
    "    return arabic_characters.search(text) is not None\n",
    "\n",
    "# Remove rows with Arabic titles\n",
    "youtube_data = youtube_data[~youtube_data['title'].apply(contains_arabic)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing target values\n",
    "youtube_data = youtube_data.dropna(subset=['view_count'])\n",
    "\n",
    "# Fill missing values for text fields with empty string\n",
    "youtube_data['title'] = youtube_data['title'].fillna('')\n",
    "youtube_data['description'] = youtube_data['description'].fillna('')\n",
    "youtube_data['tags'] = youtube_data['tags'].fillna('')\n",
    "\n",
    "# Convert duration to seconds\n",
    "def duration_to_seconds(duration):\n",
    "    try:\n",
    "        duration = isodate.parse_duration(duration)\n",
    "        return duration.total_seconds()\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "youtube_data['duration_seconds'] = youtube_data['duration'].apply(duration_to_seconds)\n",
    "\n",
    "# Convert channel_creation_date to the number of days since channel creation\n",
    "youtube_data['channel_creation_date'] = pd.to_datetime(youtube_data['channel_creation_date']).dt.tz_localize(None)\n",
    "youtube_data['days_since_channel_creation'] = (pd.Timestamp.now().normalize() - youtube_data['channel_creation_date']).dt.days\n",
    "\n",
    "# Ensure 'is_for_kids' is binary\n",
    "youtube_data['is_for_kids'] = youtube_data['is_for_kids'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features that are available at the time of video creation\n",
    "features = ['title', 'description', 'tags', 'category_id', 'category_name', 'duration_seconds', \n",
    "            'channel_video_count', 'days_since_channel_creation', 'is_for_kids', 'subscriber_count']\n",
    "target = 'view_count'\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(youtube_data[features], youtube_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to preprocess text (remove special characters, tokenize, remove stopwords)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\W', ' ', text.lower())\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['title'] = X_train['title'].apply(preprocess)\n",
    "X_train['description'] = X_train['description'].apply(preprocess)\n",
    "X_train['tags'] = X_train['tags'].apply(preprocess)\n",
    "X_test['title'] = X_test['title'].apply(preprocess)\n",
    "X_test['description'] = X_test['description'].apply(preprocess)\n",
    "X_test['tags'] = X_test['tags'].apply(preprocess)\n",
    "\n",
    "# Define the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('title', TfidfVectorizer(max_features=5000), 'title'),\n",
    "        ('description', TfidfVectorizer(max_features=5000), 'description'),\n",
    "        ('tags', TfidfVectorizer(max_features=5000), 'tags'),\n",
    "        #('category_id', OneHotEncoder(), ['category_id']),\n",
    "        ('category_name', OneHotEncoder(), ['category_name']),\n",
    "        ('duration', SimpleImputer(strategy='median'), ['duration_seconds']),\n",
    "        ('channel_video_count', SimpleImputer(strategy='median'), ['channel_video_count']),\n",
    "        ('days_since_channel_creation', SimpleImputer(strategy='median'), ['days_since_channel_creation']),\n",
    "        ('is_for_kids', 'passthrough', ['is_for_kids']),\n",
    "        ('subscriber_count', SimpleImputer(strategy='median'), ['subscriber_count'])\n",
    "    ], sparse_threshold=0)  # Ensure dense output\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3115584.241200084\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youtube_view_predictor.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'youtube_view_predictor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Views: 512,736\n"
     ]
    }
   ],
   "source": [
    "# Example of new video data\n",
    "new_video = pd.DataFrame({\n",
    "    'title': ['New Video Title'],\n",
    "    'description': ['This is a description of the new video.'],\n",
    "    'tags': ['tag1 tag2 tag3'],\n",
    "    'category_id': [24],\n",
    "    'category_name': ['Entertainment'],\n",
    "    'duration_seconds': [300],\n",
    "    'channel_video_count': [150],\n",
    "    'days_since_channel_creation': [(pd.Timestamp.now() - pd.Timestamp('2020-01-01')).days],\n",
    "    'is_for_kids': [0],\n",
    "    'subscriber_count': [100000]\n",
    "})\n",
    "\n",
    "# Preprocess the new video data\n",
    "new_video['title'] = new_video['title'].apply(preprocess)\n",
    "new_video['description'] = new_video['description'].apply(preprocess)\n",
    "new_video['tags'] = new_video['tags'].apply(preprocess)\n",
    "\n",
    "# Predict views\n",
    "predicted_views = model.predict(new_video)\n",
    "print(f'Predicted Views: {predicted_views[0]:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f2m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
